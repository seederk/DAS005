 # E2 - Classifica√ß√£o com Regress√£o Log√≠stica (An√°lise cr√©dito)

‚ÄúSouth German Credit‚Äù √© uma base com informa√ß√µes de 1000 cr√©ditos (700 good and 300 bad) com 20 vari√°veis preditoras.

Objetivo: desenvolver um modelo de predi√ß√£o do risco de cr√©dito (0 = bom; 1 = ruim)

- Importando as bibliotecas

```python
import pandas as pd
import numpy as np
import statsmodels
import seaborn
from matplotlib import pyplot as plt
pd.options.display.max_columns = 100
pd.options.mode.chained_assignment = None  # default='warn'
```
- Importando a base de dados
```python
df = pd.read_csv('base_2sgc.csv')
print(df.shape)
```

- Visualizando uma amostra da base
```python
 df.head()
```

## 1 - An√°lise descritiva de vari√°veis

1.1 Estat√≠sticas descritivas: frequ√™ncia, tabelas cruzadas, m√©dia (ùë•¬Ø), desvio padr√£o (ùë†), quartis (ùëÑ1, ùë•ÃÉ , ùëÑ3)      (2,0)

- Avaliando o tipo das vari√°veis na base
```python
 df.info()
```

- An√°lise descritiva para vari√°veis num√©ricas
```python
 df.describe()
```
- An√°lise descritiva das vari√°veis categ√≥ricas
```python
df.describe(include=object)
```
```python
plt.rcParams["figure.figsize"] = (20,10)
for i, x in enumerate(df.dtypes):
  if x == 'object':
    #print(pd.crosstab(index=df[df.columns[i]], columns='freq', dropna=False))
    print(pd.crosstab(df[df.columns[i]], df['credit_risk']).apply(lambda r: r/r.sum(), axis=0))
    print('')
```
1.2 Gr√°ficos como: Gr√°ficos de colunas, BoxPlot por categorias          (2,0)
```python
import seaborn as sns

for i, x in enumerate(df.dtypes):
   if x == 'int64' or x == 'float64':
       plt.figure(i)
       sns.boxplot(data = df, y = df[df.columns[i]], hue = df['credit_risk'])
   elif x == 'object':
       plt.figure(i)
       sns.countplot(x=df[df.columns[i]], hue = 'credit_risk', data=df)
```

## 2 - Desenvolvimento de modelo de Classifica√ß√£o utilizando Regress√£o Log√≠stica (binomial).

- Primeiramente realizamos um tratamento nas variaveis
```python
cols = df.columns
num_data = list(df._get_numeric_data().columns)
categorical_data = list(set(cols) - set(num_data) - set(['credit_risk']))
Y = df.credit_risk
X_cat = df[categorical_data]
X_num_data = df[num_data]

factorize_cols = ['status', 'savings', 'employment_duration', 'installment_rate', 'present_residence', 'number_credits', 'people_liable']

dummies_cols = list(set(categorical_data) - set(factorize_cols))
```

```python

cat_status = ["no checking account", "... < 0 DM", "0<= ... < 200 DM", "... >= 200 DM / salary for at least 1 year"]
cat_savings = ["unknown/no savings account", "... <  100 DM", "100 <= ... <  500 DM", "500 <= ... < 1000 DM", "... >= 1000 DM"]
cat_employment_duration = ["unemployed", "< 1 yr", "1 <= ... < 4 yrs", "4 <= ... < 7 yrs", ">= 7 yrs"]
cat_installment_rate = [">= 35", "25 <= ... < 35", "20 <= ... < 25", "< 20"]
cat_present_residence = ["< 1 yr", "1 <= ... < 4 yrs", "4 <= ... < 7 yrs", ">= 7 yrs"]
cat_number_credits = ["1", "2-3", "4-5", ">= 6"]
cat_people_liable = ["3 or more", "0 to 2"]

X_cat['status'] = pd.factorize(pd.Categorical(X_cat['status'], categories = cat_status))[0]
X_cat['savings'] = pd.factorize(pd.Categorical(X_cat['savings'], categories = cat_savings))[0]
X_cat['employment_duration'] = pd.factorize(pd.Categorical(X_cat['employment_duration'], categories = cat_employment_duration))[0]
X_cat['installment_rate'] = pd.factorize(pd.Categorical(X_cat['installment_rate'], categories = cat_installment_rate))[0]
X_cat['present_residence'] = pd.factorize(pd.Categorical(X_cat['present_residence'], categories = cat_present_residence))[0]
X_cat['number_credits'] = pd.factorize(pd.Categorical(X_cat['number_credits'], categories = cat_number_credits))[0]
X_cat['people_liable'] = pd.factorize(pd.Categorical(X_cat['people_liable'], categories = cat_people_liable))[0]

X_cat= pd.get_dummies(X_cat)

Y = pd.factorize(Y)[0]

def robust_scaling(df):
    df_robust = df.copy()
    for column in df_robust.columns:
        df_robust[column] = (df_robust[column] - df_robust[column].median())/(df_robust[column].quantile(0.75) - df_robust[column].quantile(0.25))
    return df_robust

X_num_data = robust_scaling(X_num_data)


X = pd.concat([X_cat, X_num_data], axis = 1)

```
Importando as bibliotecas de ML
```python
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
```
2.1 Descri√ß√£o da amostra de treino e de teste        (0,5)

Aplicamos uma taxa de amostragem para teste de 20%, deixando 80% para treino e estratificado para manter a mesma propor√ßao de bons e mals nas duas amostras.
```python
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1234, stratify=Y)

log_reg = LogisticRegression()
log = log_reg.fit(X_train, y_train)
y_pred = log.predict(X_train)
y_predtest = log.predict(X_test)
print("train score: ", log.score(X_train,y_train))
print("test score: ", log.score(X_test,y_test))
```
2.2 Descri√ß√£o do modelo, coeficientes, signific√¢ncia obtida        (2,0)
```python
odds = np.exp(log.coef_[0])/(1 + np.exp(log.coef_[0]))
coeficientes = pd.DataFrame(odds,
             X_train.columns,
             columns=['coef'])\
            .sort_values(by='coef', ascending=False)
print(coeficientes)
print(" ")
plt.rcParams["figure.figsize"] = (20,10)
plt.plot(log.coef_.T, 'o', label = "teste")
plt.xticks(range(X_train.shape[1]), X_train.columns, rotation=90)
plt.hlines(0,0, X_train.shape[1])
```
A partir do resultado acima podemos notar que as vari√°veis mais importantes
fazem sentido dado que o hist√≥rico de atraso no passado, prop√≥sito do empr√©stimo sem defini√ßao
podendo ser um emprestimo sem garantia, para fins de reparo tambem podem ser creditos
mais arriscado dado que n√£o necessariamente a um valor agregado para aquele montante emprestado.
Por fim, cr√©dito em outros bancos j√° mostra um individamento maior do indiv√≠duo, diminuindo
sua capacidade de pagamento por j√° possuir compromisso com outras institui√ß√µes.

2.3 Curva ROC obtida no treino - an√°lise                 (1,0)
```python
from sklearn.metrics import roc_curve
plt.rcParams["figure.figsize"] = (20,10)
fpr, tpr, thresholds = roc_curve(y_train, y_pred)

def plot_roc(fpr, tpr, thresholds):
  plt.plot(fpr, tpr, label=None)
  plt.plot([0,1], [0,1], 'k--')
  plt.axis([0,1,0,1])
  plt.xlabel("Taxa de Falso positivo")
  plt.ylabel("Taxa de Verdadeiros positivos")

plot_roc(fpr, tpr, thresholds)
plt.show()
```
2.4 Medidas de desempenho para amostra de treino e para a amostra de teste: Matriz confus√£o, precis√£o, revoca√ß√£o, ùêπ1        (2,5)
```python
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
print('treino')
print('matriz de confus√£o: ')
print(confusion_matrix(y_train, y_pred))
print('Precision: ', precision_score(y_train, y_pred))
print('Recall: ', recall_score(y_train, y_pred))
print('F1: ', f1_score(y_train, y_pred))

print('teste')
print('matriz de confus√£o: ')
print(confusion_matrix(y_test, y_predtest))
print('Precision: ', precision_score(y_test, y_predtest))
print('Recall: ', recall_score(y_test, y_predtest))
print('F1: ', f1_score(y_test, y_predtest))
```
## Conclus√£o

  Pelos resultados obtidos podemos concluir que o modelo n√£o possui overffiting.
  Apesar do ajuste apresentar uma acur√°ria de 78%, a partir dos resultados da matriz de confus√£o
  √© poss√≠vel dizer que o modelo n√£o classifica bem os mal pagadores.
